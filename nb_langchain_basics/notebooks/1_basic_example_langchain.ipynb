{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute succesfully this notebook you should to install the following requirements:\n",
    "\n",
    "* `langchain==0.1.11`\n",
    "* `openai==1.13.3`\n",
    "* `PyPDF2==3.0.1`\n",
    "* `faiss-cpu==1.8.0`\n",
    "* `tiktoken==0.6.0`\n",
    "* `pandas`\n",
    "* `pydantic==2.6.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('config.json') as config_file:\n",
    "#     config = json.load(config_file)\n",
    "#     open_api_key = config['openai_api_key']\n",
    "\n",
    "# print(open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Carga las variables de entorno desde .env\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpalacioj/miniconda3/envs/nlp_study/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpalacioj/miniconda3/envs/nlp_study/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As an AI, I do not have access to specific information about individuals. It is best to research David Palacio's accomplishments and awards to find the accurate number.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"How many awards did David Palacio won?\"\n",
    "print(llm(our_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.llms.openai.OpenAI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Call a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo no encontrado en la ruta especificada: /mnt/d/projects/udemy/llm-to-production/nb_langchain_basics/notebooks/data/dpj_description.pdf\n"
     ]
    }
   ],
   "source": [
    "# Obtener el directorio de trabajo actual en el notebook\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Construir la ruta al archivo PDF\n",
    "file_path = os.path.join(base_dir, \"data\", \"dpj_description.pdf\")\n",
    "\n",
    "# Verificar si el archivo existe y leer el PDF\n",
    "if os.path.exists(file_path):\n",
    "    data = PdfReader(file_path)\n",
    "    for page in data.pages:\n",
    "        print(page.extract_text())\n",
    "else:\n",
    "    print(\"Archivo no encontrado en la ruta especificada:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual de trabajo: /mnt/d/projects/udemy/llm-to-production/nb_langchain_basics/notebooks\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(\"Directorio actual de trabajo:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\dpj_description.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdpj_description.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_study/lib/python3.10/site-packages/PyPDF2/_reader.py:317\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    311\u001b[0m     logger_warning(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may not be read correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\dpj_description.pdf'"
     ]
    }
   ],
   "source": [
    "data = PdfReader(r'..\\data\\dpj_description.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'/Author': 'XXXXX', '/Creator': 'Microsoft® Word 2019', '/CreationDate': \"D:20240307220345-05'00'\", '/ModDate': \"D:20240307220345-05'00'\", '/Producer': 'Microsoft® Word 2019'}\n"
     ]
    }
   ],
   "source": [
    "print(len(data.pages))\n",
    "print(data.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David is a Colombian g uy dedicated to be a n AI engineer focu sed on Generative AI models, regression \n",
      "models and unbalanced cases associated with geological problems.  \n",
      " \n",
      "David was awarded a scholarship for his Master of Science  degree in Analytics . Also he took sexond place \n",
      "in chess tournaments in the department of Antioquia – Colombia.  \n",
      " \n",
      "He is 29 years old.  \n",
      "\n",
      "\n",
      "<class 'str'>\n",
      "\n",
      "\n",
      "La cantidad de caracteres que tiene el pdf corresponden a: 370\n"
     ]
    }
   ],
   "source": [
    "combined_text = ''\n",
    "for i, page in enumerate(data.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        combined_text += text\n",
    "    \n",
    "print(combined_text)\n",
    "print(\"\\n\")\n",
    "print(type(combined_text))\n",
    "print(\"\\n\")\n",
    "print(\"La cantidad de caracteres que tiene el pdf corresponden a: \" + str(len(combined_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "text = page.extract_text()\n",
    "text\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['David is a Colombian g uy dedicated to be a n AI engineer focu sed on Generative AI models, regression \\nmodels and unbalanced cases associated with geological problems.  \\n \\nDavid was awarded a scholarship for his Master of Science  degree in Analytics . Also he took sexond place \\nin chess tournaments in the department of Antioquia – Colombia.  \\n \\nHe is 29 years old.']\n",
      "\n",
      "\n",
      "<class 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 370,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "finalData = text_splitter.split_text(combined_text)\n",
    "print(finalData)\n",
    "print(\"\\n\")\n",
    "print(type(finalData))\n",
    "print(len(finalData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David was awarded a scholarship for his Master of Science  degree in Analytics . Also he took sexond place \\nin chess tournaments in the department of Antioquia – Colombia.  \\n \\nHe is 29 years old.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finalData[0]\n",
    "finalData[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. To see more information click [here](https://python.langchain.com/docs/integrations/vectorstores/faiss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentSearch = FAISS.from_texts(finalData, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(openai_api_key=open_api_key), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DAVIDPJ\\david\\envs\\udemy_llm\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' David Palacio is 29 years old.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_query = \"How old is David Palacio?\"\n",
    "docs = documentSearch.similarity_search(our_query)\n",
    "chain.run(input_documents=docs, question=our_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
